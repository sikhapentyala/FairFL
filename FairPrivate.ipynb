{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_docs as tfdocs\n",
    "import tensorflow_docs.modeling\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import datetime\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "from typing import Dict, Any, Union, List, Tuple\n",
    "from functools import partial\n",
    "import re\n",
    "import string\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from math import ceil\n",
    "from collections import namedtuple\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "\n",
    "import chakin\n",
    "import json\n",
    "import os\n",
    "from collections import defaultdict\n",
    "import zipfile\n",
    "import sqlite3\n",
    "import logging\n",
    "from tempfile import TemporaryDirectory\n",
    "from fastprogress import progress_bar\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import NearMiss\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import concatenate\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.regularizers import L2\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.regularizers import l2\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import NearMiss\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "#from EmbeddingFactory import EmbeddingFactory\n",
    "from sklearn.metrics import roc_auc_score, classification_report, precision_score, recall_score, auc,average_precision_score, f1_score, accuracy_score, precision_recall_curve\n",
    "\n",
    "from numpy.random import seed\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "print(f\"Using Tensorflow, {tf.__version__} on Python interpreter, {sys.version_info}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RANDOM SET SEED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 47568\n",
    "seed(47568)\n",
    "#tf.random.set_random_seed(seed_value)\n",
    "os.environ['PYTHONHASHSEED']=str(47568)\n",
    "random.seed(47568)\n",
    "tf.random.set_seed(47568)\n",
    "\n",
    "SAVE = False\n",
    "\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "print(f\"Using random seed, {RANDOM_SEED}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '/Users/sikha/0FAIRFL/Data/113p/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.load(DATA_PATH+\"X_train.npy\",allow_pickle=True)\n",
    "y_train = np.load(DATA_PATH+\"y_train.npy\",allow_pickle=True)\n",
    "X_test = np.load(DATA_PATH+\"X_test.npy\",allow_pickle=True)\n",
    "y_test = np.load(DATA_PATH+\"y_test.npy\",allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_pickle(DATA_PATH+\"testdf.pkl\")\n",
    "train_df = pd.read_pickle(DATA_PATH+\"traindf.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sensitive attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single Binary sensitive attribute and Binary classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SENS_ATTR = 'Female' \n",
    "# gender column OHE\n",
    "\n",
    "LABEL_NAME = 'Rating'\n",
    "PROT_ATTR_NAME = 'Female'\n",
    "UNPROT_ATTR_NAME = 'Male'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODELS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Central -SKLEARN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_model = LogisticRegression(random_state = RANDOM_SEED, solver='sag',max_iter=10000)\n",
    "lr_model.fit(X_train,y_train.ravel())\n",
    "y_prob = lr_model.predict_proba(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lr_model.n_iter_)\n",
    "print(\"ROC AUC: \", roc_auc_score(y_test.ravel(), y_prob[:,1]))\n",
    "precision, recall, _ = precision_recall_curve(y_test.ravel(), y_prob[:,1])\n",
    "auc_score = auc(recall, precision)\n",
    "print('PR AUC: %.3f' % auc_score)\n",
    "print(\"AP: \", average_precision_score(y_test.ravel(), y_prob[:,1]))\n",
    "tn, fp, fn, tp = confusion_matrix(y_test,np.argmax(y_prob, axis = 1).ravel(), labels=[0, 1]).ravel()\n",
    "print(\"TPR OA:\", tp/(tp+fn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['pred'] = np.argmax(y_prob, axis = 1)\n",
    "test_df['pred'] = test_df['pred'].astype('int')\n",
    "\n",
    "prot_df = test_df[test_df[PROT_ATTR_NAME] == 1][[LABEL_NAME,'pred']]\n",
    "tn, fp, fn, tp = confusion_matrix(prot_df[[LABEL_NAME]].values.ravel(),prot_df[['pred']].values.ravel(), labels=[0, 1]).ravel()\n",
    "prot_tpr = tp/(tp+fn)\n",
    "print(PROT_ATTR_NAME,\":\", tp/(tp+fn))\n",
    "\n",
    "unprot_df = test_df[test_df[UNPROT_ATTR_NAME] == 1][[LABEL_NAME,'pred']]\n",
    "tn, fp, fn, tp = confusion_matrix(unprot_df[[LABEL_NAME]].values.ravel(),unprot_df[['pred']].values.ravel(), labels=[0, 1]).ravel()\n",
    "unprot_tpr = tp/(tp+fn)\n",
    "print(UNPROT_ATTR_NAME,\":\", tp/(tp+fn))\n",
    "\n",
    "print(\"DI:\", max(prot_tpr/unprot_tpr, unprot_tpr/prot_tpr))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Central - KERAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# T have similarity and better perf 2 units so reshaping y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_2 = []\n",
    "for label in y_train:\n",
    "    if label == 1:\n",
    "        x = [0,1]\n",
    "    else:\n",
    "        x = [1,0]\n",
    "    y_train_2.append(np.array(x))\n",
    "y_train_2 = np.array(y_train_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_model = Sequential()\n",
    "keras_model.add(Dense(units=2,kernel_initializer='glorot_uniform', activation='sigmoid',kernel_regularizer=l2(0.)))\n",
    "keras_model.compile(optimizer='sgd',\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=[tf.keras.metrics.Recall()])\n",
    "hist = keras_model.fit(X_train, y_train_2,batch_size=64, epochs=630)#validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prob_keras  = keras_model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ROC AUC: \", roc_auc_score(y_test.ravel(), y_prob_keras[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(np.argmax(y_prob_m2, axis = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_model.save(DATA_PATH+\"model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['pred_k'] = np.argmax(y_prob_keras, axis = 1)\n",
    "test_df['pred_k'] = test_df['pred_k'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "prot_df = test_df[test_df[PROT_ATTR_NAME] == 1][[LABEL_NAME,'pred_k']]\n",
    "tn, fp, fn, tp = confusion_matrix(prot_df[[LABEL_NAME]].values.ravel(),prot_df[['pred_k']].values.ravel(), labels=[0, 1]).ravel()\n",
    "prot_tpr = tp/(tp+fn)\n",
    "print(PROT_ATTR_NAME,\":\", tp/(tp+fn))\n",
    "\n",
    "unprot_df = test_df[test_df[UNPROT_ATTR_NAME] == 1][[LABEL_NAME,'pred_k']]\n",
    "tn, fp, fn, tp = confusion_matrix(unprot_df[[LABEL_NAME]].values.ravel(),unprot_df[['pred_k']].values.ravel(), labels=[0, 1]).ravel()\n",
    "unprot_tpr = tp/(tp+fn)\n",
    "print(UNPROT_ATTR_NAME,\":\", tp/(tp+fn))\n",
    "\n",
    "print(\"DI:\", max(prot_tpr/unprot_tpr, unprot_tpr/prot_tpr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reweighing techniques - collect stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#count(s=female)\n",
    "cs1 = train_df[PROT_ATTR_NAME].sum()\n",
    "#count(s=female)\n",
    "cs0 = train_df[UNPROT_ATTR_NAME].sum()\n",
    "#count(y=1)\n",
    "cy1 = train_df[LABEL_NAME].sum()\n",
    "#count(y=0)\n",
    "cy0 = train_df.shape[0] - cy1\n",
    "\n",
    "print(cs1, cs0)\n",
    "print(cy1, cy0)\n",
    "\n",
    "cs0y0 = train_df[(train_df[PROT_ATTR_NAME]==0) & (train_df[LABEL_NAME]==0)].shape[0]\n",
    "cs0y1 = train_df[(train_df[PROT_ATTR_NAME]==0) & (train_df[LABEL_NAME]==1)].shape[0]\n",
    "cs1y0 = train_df[(train_df[PROT_ATTR_NAME]==1) & (train_df[LABEL_NAME]==0)].shape[0]\n",
    "cs1y1 = train_df[(train_df[PROT_ATTR_NAME]==1) & (train_df[LABEL_NAME]==1)].shape[0]\n",
    "print(cs0y0,cs0y1)\n",
    "print(cs1y0,cs1y1)\n",
    "tot = X_train.shape[0]\n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FairBalanceClass\n",
    "### 1 / count(y and a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def assignweights_fb(x):\n",
    "    if x[PROT_ATTR_NAME] == 0 and x[LABEL_NAME] == 0:\n",
    "        return 1/cs0y0\n",
    "    if x[PROT_ATTR_NAME] == 0 and x[LABEL_NAME] == 1:\n",
    "        return 1/cs0y1\n",
    "    if x[PROT_ATTR_NAME] == 1 and x[LABEL_NAME] == 0:\n",
    "        return 1/cs1y0\n",
    "    if x[PROT_ATTR_NAME] == 1 and x[LABEL_NAME] == 1:\n",
    "        return 1/cs1y1  \n",
    "\n",
    "train_df['weights_fb'] = train_df[[PROT_ATTR_NAME,LABEL_NAME]].apply(assignweights_fb, axis=1)\n",
    "sample_weights = train_df['weights_fb'].values.ravel() \n",
    "sample_weights = sample_weights * len(y_train.ravel()) / sum(sample_weights)    \n",
    "\n",
    "\n",
    "fb_model = LogisticRegression(random_state = RANDOM_SEED, solver='sag',max_iter=10000)\n",
    "fb_model.fit(X_train,y_train.ravel(),sample_weights)\n",
    "y_prob_fb_bal = fb_model.predict_proba(X_test)\n",
    "print(lr_model_fb_bal.n_iter_)\n",
    "print(\"ROC AUC: %.3f\" %  roc_auc_score(y_test.ravel(), y_prob_fb_bal[:,1]))\n",
    "\n",
    "test_df['pred_fb_bal'] = np.argmax(y_prob_fb_bal, axis = 1)\n",
    "test_df['pred_fb_bal'] = test_df['pred_fb_bal'].astype('int')\n",
    "\n",
    "prot_df = test_df[test_df[PROT_ATTR_NAME] == 1][[LABEL_NAME,'pred_fb_bal']]\n",
    "tn, fp, fn, tp = confusion_matrix(prot_df[[LABEL_NAME]].values.ravel(),prot_df[['pred_fb_bal']].values.ravel(), labels=[0, 1]).ravel()\n",
    "prot_tpr = tp/(tp+fn)\n",
    "print(PROT_ATTR_NAME,\":\", tp/(tp+fn))\n",
    "\n",
    "unprot_df = test_df[test_df[UNPROT_ATTR_NAME] == 1][[LABEL_NAME,'pred_fb_bal']]\n",
    "tn, fp, fn, tp = confusion_matrix(unprot_df[[LABEL_NAME]].values.ravel(),unprot_df[['pred_fb_bal']].values.ravel(), labels=[0, 1]).ravel()\n",
    "unprot_tpr = tp/(tp+fn)\n",
    "print(UNPROT_ATTR_NAME,\":\", tp/(tp+fn))\n",
    "\n",
    "print(\"DI:\", max(prot_tpr/unprot_tpr, unprot_tpr/prot_tpr))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_b = Sequential()\n",
    "model_b.add(Dense(units=2,kernel_initializer='glorot_uniform', activation='sigmoid',kernel_regularizer=l2(0.)))\n",
    "model_b.compile(optimizer='sgd',\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=[tf.keras.metrics.Recall()])\n",
    "model_b.fit(X_train, y_train_2,sample_weight=sample_weights,batch_size=64, epochs=700)#validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prob_fb_bal_k  = model_b2.predict(X_test)\n",
    "print(\"ROC AUC: \", roc_auc_score(y_test.ravel(), y_prob_fb_bal_k[:,1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_df['pred_fb_bal'] = np.argmax(y_prob_fb_bal_k, axis = 1)\n",
    "test_df['pred_fb_bal'] = test_df['pred_fb_bal'].astype('int')\n",
    "\n",
    "prot_df = test_df[test_df[PROT_ATTR_NAME] == 1][[LABEL_NAME,'pred_fb_bal']]\n",
    "tn, fp, fn, tp = confusion_matrix(prot_df[[LABEL_NAME]].values.ravel(),prot_df[['pred_fb_bal']].values.ravel(), labels=[0, 1]).ravel()\n",
    "prot_tpr = tp/(tp+fn)\n",
    "print(PROT_ATTR_NAME,\":\", tp/(tp+fn))\n",
    "\n",
    "unprot_df = test_df[test_df[UNPROT_ATTR_NAME] == 1][[LABEL_NAME,'pred_fb_bal']]\n",
    "tn, fp, fn, tp = confusion_matrix(unprot_df[[LABEL_NAME]].values.ravel(),unprot_df[['pred_fb_bal']].values.ravel(), labels=[0, 1]).ravel()\n",
    "unprot_tpr = tp/(tp+fn)\n",
    "print(UNPROT_ATTR_NAME,\":\", tp/(tp+fn))\n",
    "\n",
    "print(\"DI:\", max(prot_tpr/unprot_tpr, unprot_tpr/prot_tpr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FairBalance\n",
    "### count(y) / count(y and a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def assignweights_fb(x):\n",
    "    if x[PROT_ATTR_NAME] == 0 and x[LABEL_NAME] == 0:\n",
    "        return cy0/cs0y0\n",
    "    if x[PROT_ATTR_NAME] == 0 and x[LABEL_NAME] == 1:\n",
    "        return cy1/cs0y1\n",
    "    if x[PROT_ATTR_NAME] == 1 and x[LABEL_NAME] == 0:\n",
    "        return cy0/cs1y0\n",
    "    if x[PROT_ATTR_NAME] == 1 and x[LABEL_NAME] == 1:\n",
    "        return cy1/cs1y1  \n",
    "\n",
    "    \n",
    "train_df['weights_fb'] = train_df[[PROT_ATTR_NAME,LABEL_NAME]].apply(assignweights_fb, axis=1)\n",
    "sample_weights = train_df['weights_fb'].values.ravel() \n",
    "sample_weights = sample_weights * len(y_train.ravel()) / sum(sample_weights)    \n",
    "\n",
    "\n",
    "fb_model = LogisticRegression(random_state = RANDOM_SEED, solver='sag',max_iter=10000)\n",
    "fb_model.fit(X_train,y_train.ravel(),sample_weights)\n",
    "y_prob_fb_bal = fb_model.predict_proba(X_test)\n",
    "print(lr_model_fb_bal.n_iter_)\n",
    "print(\"ROC AUC: %.3f\" %  roc_auc_score(y_test.ravel(), y_prob_fb_bal[:,1]))\n",
    "\n",
    "test_df['pred_fb_bal'] = np.argmax(y_prob_fb_bal, axis = 1)\n",
    "test_df['pred_fb_bal'] = test_df['pred_fb_bal'].astype('int')\n",
    "\n",
    "prot_df = test_df[test_df[PROT_ATTR_NAME] == 1][[LABEL_NAME,'pred_fb_bal']]\n",
    "tn, fp, fn, tp = confusion_matrix(prot_df[[LABEL_NAME]].values.ravel(),prot_df[['pred_fb_bal']].values.ravel(), labels=[0, 1]).ravel()\n",
    "prot_tpr = tp/(tp+fn)\n",
    "print(PROT_ATTR_NAME,\":\", tp/(tp+fn))\n",
    "\n",
    "unprot_df = test_df[test_df[UNPROT_ATTR_NAME] == 1][[LABEL_NAME,'pred_fb_bal']]\n",
    "tn, fp, fn, tp = confusion_matrix(unprot_df[[LABEL_NAME]].values.ravel(),unprot_df[['pred_fb_bal']].values.ravel(), labels=[0, 1]).ravel()\n",
    "unprot_tpr = tp/(tp+fn)\n",
    "print(UNPROT_ATTR_NAME,\":\", tp/(tp+fn))\n",
    "\n",
    "print(\"DI:\", max(prot_tpr/unprot_tpr, unprot_tpr/prot_tpr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FairBalance2\n",
    "### 1 / count(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assignweights_fb(x):\n",
    "    if x[PROT_ATTR_NAME] == 0 and x[LABEL_NAME] == 0:\n",
    "        return 1/(cs0)\n",
    "    if x[PROT_ATTR_NAME] == 0 and x[LABEL_NAME] == 1:\n",
    "        return 1/(cs0)\n",
    "    if x[PROT_ATTR_NAME] == 1 and x[LABEL_NAME] == 0:\n",
    "        return 1/(cs1)\n",
    "    if x[PROT_ATTR_NAME] == 1 and x[LABEL_NAME] == 1:\n",
    "        return 1/(cs1)  \n",
    "\n",
    "    \n",
    "train_df['weights_fb'] = train_df[[PROT_ATTR_NAME,LABEL_NAME]].apply(assignweights_fb, axis=1)\n",
    "sample_weights = train_df['weights_fb'].values.ravel() \n",
    "sample_weights = sample_weights * len(y_train.ravel()) / sum(sample_weights)    \n",
    "\n",
    "\n",
    "fb_model = LogisticRegression(random_state = RANDOM_SEED, solver='sag',max_iter=10000)\n",
    "fb_model.fit(X_train,y_train.ravel(),sample_weights)\n",
    "y_prob_fb_bal = fb_model.predict_proba(X_test)\n",
    "print(lr_model_fb_bal.n_iter_)\n",
    "print(\"ROC AUC: %.3f\" %  roc_auc_score(y_test.ravel(), y_prob_fb_bal[:,1]))\n",
    "\n",
    "test_df['pred_fb_bal'] = np.argmax(y_prob_fb_bal, axis = 1)\n",
    "test_df['pred_fb_bal'] = test_df['pred_fb_bal'].astype('int')\n",
    "\n",
    "prot_df = test_df[test_df[PROT_ATTR_NAME] == 1][[LABEL_NAME,'pred_fb_bal']]\n",
    "tn, fp, fn, tp = confusion_matrix(prot_df[[LABEL_NAME]].values.ravel(),prot_df[['pred_fb_bal']].values.ravel(), labels=[0, 1]).ravel()\n",
    "prot_tpr = tp/(tp+fn)\n",
    "print(PROT_ATTR_NAME,\":\", tp/(tp+fn))\n",
    "\n",
    "unprot_df = test_df[test_df[UNPROT_ATTR_NAME] == 1][[LABEL_NAME,'pred_fb_bal']]\n",
    "tn, fp, fn, tp = confusion_matrix(unprot_df[[LABEL_NAME]].values.ravel(),unprot_df[['pred_fb_bal']].values.ravel(), labels=[0, 1]).ravel()\n",
    "unprot_tpr = tp/(tp+fn)\n",
    "print(UNPROT_ATTR_NAME,\":\", tp/(tp+fn))\n",
    "\n",
    "print(\"DI:\", max(prot_tpr/unprot_tpr, unprot_tpr/prot_tpr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FairBalanceClass2\n",
    "### 1 / (count(y) * count(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assignweights_fb(x):\n",
    "    if x[PROT_ATTR_NAME] == 0 and x[LABEL_NAME] == 0:\n",
    "        return 1/(cs0 * cy0)\n",
    "    if x[PROT_ATTR_NAME] == 0 and x[LABEL_NAME] == 1:\n",
    "        return 1/(cs0 * cy1)\n",
    "    if x[PROT_ATTR_NAME] == 1 and x[LABEL_NAME] == 0:\n",
    "        return 1/(cs1 * cy0)\n",
    "    if x[PROT_ATTR_NAME] == 1 and x[LABEL_NAME] == 1:\n",
    "        return 1/(cs1 * cy1) \n",
    "\n",
    "    \n",
    "train_df['weights_fb'] = train_df[[PROT_ATTR_NAME,LABEL_NAME]].apply(assignweights_fb, axis=1)\n",
    "sample_weights = train_df['weights_fb'].values.ravel() \n",
    "sample_weights = sample_weights * len(y_train.ravel()) / sum(sample_weights)    \n",
    "\n",
    "\n",
    "fb_model = LogisticRegression(random_state = RANDOM_SEED, solver='sag',max_iter=10000)\n",
    "fb_model.fit(X_train,y_train.ravel(),sample_weights)\n",
    "y_prob_fb_bal = fb_model.predict_proba(X_test)\n",
    "print(lr_model_fb_bal.n_iter_)\n",
    "print(\"ROC AUC: %.3f\" %  roc_auc_score(y_test.ravel(), y_prob_fb_bal[:,1]))\n",
    "\n",
    "test_df['pred_fb_bal'] = np.argmax(y_prob_fb_bal, axis = 1)\n",
    "test_df['pred_fb_bal'] = test_df['pred_fb_bal'].astype('int')\n",
    "\n",
    "prot_df = test_df[test_df[PROT_ATTR_NAME] == 1][[LABEL_NAME,'pred_fb_bal']]\n",
    "tn, fp, fn, tp = confusion_matrix(prot_df[[LABEL_NAME]].values.ravel(),prot_df[['pred_fb_bal']].values.ravel(), labels=[0, 1]).ravel()\n",
    "prot_tpr = tp/(tp+fn)\n",
    "print(PROT_ATTR_NAME,\":\", tp/(tp+fn))\n",
    "\n",
    "unprot_df = test_df[test_df[UNPROT_ATTR_NAME] == 1][[LABEL_NAME,'pred_fb_bal']]\n",
    "tn, fp, fn, tp = confusion_matrix(unprot_df[[LABEL_NAME]].values.ravel(),unprot_df[['pred_fb_bal']].values.ravel(), labels=[0, 1]).ravel()\n",
    "unprot_tpr = tp/(tp+fn)\n",
    "print(UNPROT_ATTR_NAME,\":\", tp/(tp+fn))\n",
    "\n",
    "print(\"DI:\", max(prot_tpr/unprot_tpr, unprot_tpr/prot_tpr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IBM paper\n",
    "### Reweighing technique from 2012 paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "ws0y0 = ((cs0/tot) * (cy0/tot)) / (cs0y0/tot)\n",
    "ws0y1 = ((cs0/tot) * (cy1/tot)) / (cs0y1/tot)\n",
    "ws1y0 = ((cs1/tot) * (cy0/tot)) / (cs1y0/tot)\n",
    "ws1y1 = ((cs1/tot) * (cy1/tot)) / (cs1y1/tot)\n",
    "\n",
    "print(ws0y0,ws0y1,ws1y0,ws1y1)\n",
    "\n",
    "def assignweights(x):\n",
    "    if x[PROT_ATTR_NAME] == 0 and x[LABEL_NAME] == 0:\n",
    "        return ws0y0 #* tot/(2*cy0) \n",
    "    if x[PROT_ATTR_NAME] == 0 and x[LABEL_NAME] == 1:\n",
    "        return ws0y1 #* tot/(2*cy1)\n",
    "    if x[PROT_ATTR_NAME] == 1 and x[LABEL_NAME] == 0:\n",
    "        return ws1y0 #* tot/(2*cy0)\n",
    "    if x[PROT_ATTR_NAME] == 1 and x[LABEL_NAME] == 1:\n",
    "        return ws1y1 #* tot/(2*cy1)  \n",
    "    \n",
    "train_df['weights_fb'] = train_df[[PROT_ATTR_NAME,LABEL_NAME]].apply(assignweights_fb, axis=1)\n",
    "sample_weights = train_df['weights_fb'].values.ravel() \n",
    "\n",
    "fb_model = LogisticRegression(random_state = RANDOM_SEED, solver='sag',max_iter=10000)\n",
    "fb_model.fit(X_train,y_train.ravel(),sample_weights)\n",
    "y_prob_fb_bal = fb_model.predict_proba(X_test)\n",
    "print(lr_model_fb_bal.n_iter_)\n",
    "print(\"ROC AUC: %.3f\" %  roc_auc_score(y_test.ravel(), y_prob_fb_bal[:,1]))\n",
    "\n",
    "test_df['pred_fb_bal'] = np.argmax(y_prob_fb_bal, axis = 1)\n",
    "test_df['pred_fb_bal'] = test_df['pred_fb_bal'].astype('int')\n",
    "\n",
    "prot_df = test_df[test_df[PROT_ATTR_NAME] == 1][[LABEL_NAME,'pred_fb_bal']]\n",
    "tn, fp, fn, tp = confusion_matrix(prot_df[[LABEL_NAME]].values.ravel(),prot_df[['pred_fb_bal']].values.ravel(), labels=[0, 1]).ravel()\n",
    "prot_tpr = tp/(tp+fn)\n",
    "print(PROT_ATTR_NAME,\":\", tp/(tp+fn))\n",
    "\n",
    "unprot_df = test_df[test_df[UNPROT_ATTR_NAME] == 1][[LABEL_NAME,'pred_fb_bal']]\n",
    "tn, fp, fn, tp = confusion_matrix(unprot_df[[LABEL_NAME]].values.ravel(),unprot_df[['pred_fb_bal']].values.ravel(), labels=[0, 1]).ravel()\n",
    "unprot_tpr = tp/(tp+fn)\n",
    "print(UNPROT_ATTR_NAME,\":\", tp/(tp+fn))\n",
    "\n",
    "print(\"DI:\", max(prot_tpr/unprot_tpr, unprot_tpr/prot_tpr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sklearn class balance\n",
    "### tot / 2*count(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "fb_model = LogisticRegression(random_state = RANDOM_SEED,class_weight='balanced', solver='sag',max_iter=10000)\n",
    "fb_model.fit(X_train,y_train.ravel())\n",
    "y_prob_fb_bal = fb_model.predict_proba(X_test)\n",
    "print(lr_model_fb_bal.n_iter_)\n",
    "print(\"ROC AUC: %.3f\" %  roc_auc_score(y_test.ravel(), y_prob_fb_bal[:,1]))\n",
    "\n",
    "test_df['pred_fb_bal'] = np.argmax(y_prob_fb_bal, axis = 1)\n",
    "test_df['pred_fb_bal'] = test_df['pred_fb_bal'].astype('int')\n",
    "\n",
    "prot_df = test_df[test_df[PROT_ATTR_NAME] == 1][[LABEL_NAME,'pred_fb_bal']]\n",
    "tn, fp, fn, tp = confusion_matrix(prot_df[[LABEL_NAME]].values.ravel(),prot_df[['pred_fb_bal']].values.ravel(), labels=[0, 1]).ravel()\n",
    "prot_tpr = tp/(tp+fn)\n",
    "print(PROT_ATTR_NAME,\":\", tp/(tp+fn))\n",
    "\n",
    "unprot_df = test_df[test_df[UNPROT_ATTR_NAME] == 1][[LABEL_NAME,'pred_fb_bal']]\n",
    "tn, fp, fn, tp = confusion_matrix(unprot_df[[LABEL_NAME]].values.ravel(),unprot_df[['pred_fb_bal']].values.ravel(), labels=[0, 1]).ravel()\n",
    "unprot_tpr = tp/(tp+fn)\n",
    "print(UNPROT_ATTR_NAME,\":\", tp/(tp+fn))\n",
    "\n",
    "print(\"DI:\", max(prot_tpr/unprot_tpr, unprot_tpr/prot_tpr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## My method \n",
    "### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assignweights_bal(x):\n",
    "    if x[PROT_ATTR_NAME] == 0 and x[LABEL_NAME] == 0:\n",
    "        return ws0y0 * tot/(2*cy0) \n",
    "    if x[PROT_ATTR_NAME] == 0 and x[LABEL_NAME] == 1:\n",
    "        return ws0y1 * tot/(2*cy1)\n",
    "    if x[PROT_ATTR_NAME] == 1 and x[LABEL_NAME] == 0:\n",
    "        return ws1y0 * tot/(2*cy0)\n",
    "    if x[PROT_ATTR_NAME] == 1 and x[LABEL_NAME] == 1:\n",
    "        return ws1y1 * tot/(2*cy1)  \n",
    "    \n",
    "train_df['weights_fb'] = train_df[[PROT_ATTR_NAME,LABEL_NAME]].apply(assignweights_fb, axis=1)\n",
    "sample_weights = train_df['weights_fb'].values.ravel() \n",
    "\n",
    "fb_model = LogisticRegression(random_state = RANDOM_SEED,class_weight='balanced', solver='sag',max_iter=10000)\n",
    "fb_model.fit(X_train,y_train.ravel(),sample_weights)\n",
    "y_prob_fb_bal = fb_model.predict_proba(X_test)\n",
    "print(lr_model_fb_bal.n_iter_)\n",
    "print(\"ROC AUC: %.3f\" %  roc_auc_score(y_test.ravel(), y_prob_fb_bal[:,1]))\n",
    "\n",
    "test_df['pred_fb_bal'] = np.argmax(y_prob_fb_bal, axis = 1)\n",
    "test_df['pred_fb_bal'] = test_df['pred_fb_bal'].astype('int')\n",
    "\n",
    "prot_df = test_df[test_df[PROT_ATTR_NAME] == 1][[LABEL_NAME,'pred_fb_bal']]\n",
    "tn, fp, fn, tp = confusion_matrix(prot_df[[LABEL_NAME]].values.ravel(),prot_df[['pred_fb_bal']].values.ravel(), labels=[0, 1]).ravel()\n",
    "prot_tpr = tp/(tp+fn)\n",
    "print(PROT_ATTR_NAME,\":\", tp/(tp+fn))\n",
    "\n",
    "unprot_df = test_df[test_df[UNPROT_ATTR_NAME] == 1][[LABEL_NAME,'pred_fb_bal']]\n",
    "tn, fp, fn, tp = confusion_matrix(unprot_df[[LABEL_NAME]].values.ravel(),unprot_df[['pred_fb_bal']].values.ravel(), labels=[0, 1]).ravel()\n",
    "unprot_tpr = tp/(tp+fn)\n",
    "print(UNPROT_ATTR_NAME,\":\", tp/(tp+fn))\n",
    "\n",
    "print(\"DI:\", max(prot_tpr/unprot_tpr, unprot_tpr/prot_tpr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = SMOTE(random_state=42)\n",
    "X_res, y_res = sm.fit_resample(X_train, y_train.ravel())\n",
    "\n",
    "fb_model = LogisticRegression(random_state = RANDOM_SEED,class_weight='balanced', solver='sag',max_iter=10000)\n",
    "fb_model.fit(X_res,y_res)\n",
    "y_prob_fb_bal = fb_model.predict_proba(X_test)\n",
    "print(lr_model_fb_bal.n_iter_)\n",
    "print(\"ROC AUC: %.3f\" %  roc_auc_score(y_test.ravel(), y_prob_fb_bal[:,1]))\n",
    "\n",
    "test_df['pred_fb_bal'] = np.argmax(y_prob_fb_bal, axis = 1)\n",
    "test_df['pred_fb_bal'] = test_df['pred_fb_bal'].astype('int')\n",
    "\n",
    "prot_df = test_df[test_df[PROT_ATTR_NAME] == 1][[LABEL_NAME,'pred_fb_bal']]\n",
    "tn, fp, fn, tp = confusion_matrix(prot_df[[LABEL_NAME]].values.ravel(),prot_df[['pred_fb_bal']].values.ravel(), labels=[0, 1]).ravel()\n",
    "prot_tpr = tp/(tp+fn)\n",
    "print(PROT_ATTR_NAME,\":\", tp/(tp+fn))\n",
    "\n",
    "unprot_df = test_df[test_df[UNPROT_ATTR_NAME] == 1][[LABEL_NAME,'pred_fb_bal']]\n",
    "tn, fp, fn, tp = confusion_matrix(unprot_df[[LABEL_NAME]].values.ravel(),unprot_df[['pred_fb_bal']].values.ravel(), labels=[0, 1]).ravel()\n",
    "unprot_tpr = tp/(tp+fn)\n",
    "print(UNPROT_ATTR_NAME,\":\", tp/(tp+fn))\n",
    "\n",
    "print(\"DI:\", max(prot_tpr/unprot_tpr, unprot_tpr/prot_tpr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DO NOT TRY - BELOW"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FairSMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maximum = max(cs0y0,cs0y1,cs1y0,cs1y1)\n",
    "print(cs0y0,cs0y1,cs1y0,cs1y1)\n",
    "print(maximum)\n",
    "cs0y0_to_inc = maximum - cs0y0\n",
    "cs0y1_to_inc = maximum - cs0y1\n",
    "cs1y1_to_inc = maximum - cs1y1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OTHERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assignweights_plus(x):\n",
    "    if x.Female == 0 and x.Rating == 0:\n",
    "        return ws0y0 + tot/(2*cy0) \n",
    "    if x.Female == 0 and x.Rating == 1:\n",
    "        return ws0y1 + tot/(2*cy1)\n",
    "    if x.Female == 1 and x.Rating == 0:\n",
    "        return ws1y0 + tot/(2*cy0)\n",
    "    if x.Female == 1 and x.Rating == 1:\n",
    "        return ws1y1 + tot/(2*cy1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#count(s=female)\n",
    "cs1 = train_df['Female'].sum()\n",
    "#count(s=female)\n",
    "cs0 = train_df['Male'].sum()\n",
    "#count(s=old)\n",
    "ca1 = train_df[train_df['Age_bucket'] == 'old'].shape[0]\n",
    "#count(s=female)\n",
    "ca0 = train_df[train_df['Age_bucket'] != 'old'].shape[0]\n",
    "#count(y=1)\n",
    "cy1 = train_df['Rating'].sum()\n",
    "#count(y=0)\n",
    "cy0 = train_df.shape[0] - cy1\n",
    "\n",
    "print(cs1, cs0)\n",
    "print(cy1, cy0)\n",
    "\n",
    "cs0y0 = train_df[(train_df['Female']==0) & (train_df['Rating']==0)].shape[0]\n",
    "cs0y1 = train_df[(train_df['Female']==0) & (train_df['Rating']==1)].shape[0]\n",
    "cs1y0 = train_df[(train_df['Female']==1) & (train_df['Rating']==0)].shape[0]\n",
    "cs1y1 = train_df[(train_df['Female']==1) & (train_df['Rating']==1)].shape[0]\n",
    "\n",
    "ca0y0 = train_df[(train_df['Age_bucket'] != 'old') & (train_df['Rating']==0)].shape[0]\n",
    "ca0y1 = train_df[(train_df['Age_bucket'] != 'old') & (train_df['Rating']==1)].shape[0]\n",
    "ca1y0 = train_df[(train_df['Age_bucket'] == 'old') & (train_df['Rating']==0)].shape[0]\n",
    "ca1y1 = train_df[(train_df['Age_bucket'] == 'old') & (train_df['Rating']==1)].shape[0]\n",
    "print(cs0y0,cs0y1)\n",
    "print(cs1y0,cs1y1)\n",
    "tot = X_train.shape[0]\n",
    "\n",
    "ws0y0 = ((cs0/tot) * (cy0/tot)) / (cs0y0/tot)\n",
    "ws0y1 = ((cs0/tot) * (cy1/tot)) / (cs0y1/tot)\n",
    "ws1y0 = ((cs1/tot) * (cy0/tot)) / (cs1y0/tot)\n",
    "ws1y1 = ((cs1/tot) * (cy1/tot)) / (cs1y1/tot)\n",
    "\n",
    "wa0y0 = ((ca0/tot) * (cy0/tot)) / (ca0y0/tot)\n",
    "wa0y1 = ((ca0/tot) * (cy1/tot)) / (ca0y1/tot)\n",
    "wa1y0 = ((ca1/tot) * (cy0/tot)) / (ca1y0/tot)\n",
    "wa1y1 = ((ca1/tot) * (cy1/tot)) / (ca1y1/tot)\n",
    "\n",
    "print(ws0y0,ws0y1,ws1y0,ws1y1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "#   (rw1+rw2)*bal\n",
    "def assignweights_multi(x):\n",
    "    if x.Female == 0 and x.Rating == 0:\n",
    "        if x.Age_bucket == 'old':\n",
    "            p = (ws0y0 + wa1y0) * tot/(2*cy0) \n",
    "        else:\n",
    "            p = (ws0y0 + wa0y0) * tot/(2*cy0) \n",
    "        return p\n",
    "    if x.Female == 0 and x.Rating == 1:\n",
    "        if x.Age_bucket == 'old':\n",
    "            p = (ws0y1 + wa1y1) * tot/(2*cy1) \n",
    "        else:\n",
    "            p = (ws0y1 + wa0y1) * tot/(2*cy1) \n",
    "        return p\n",
    "\n",
    "    if x.Female == 1 and x.Rating == 0:\n",
    "        if x.Age_bucket == 'old':\n",
    "            p = (ws1y0 + wa1y0) * tot/(2*cy0) \n",
    "        else:\n",
    "            p = (ws1y0 + wa0y0) * tot/(2*cy0) \n",
    "        return p\n",
    "    if x.Female == 1 and x.Rating == 1:\n",
    "        if x.Age_bucket == 'old':\n",
    "            p = (ws1y1 + wa1y1) * tot/(2*cy1) \n",
    "        else:\n",
    "            p = (ws1y1 + wa0y1) * tot/(2*cy1) \n",
    "        return p\n",
    "    \n",
    "#   (rw1*rw2)*bal\n",
    "def assignweights_multi_2(x):\n",
    "    if x.Female == 0 and x.Rating == 0:\n",
    "        if x.Age_bucket == 'old':\n",
    "            p = (ws0y0 * wa1y0) * tot/(2*cy0) \n",
    "        else:\n",
    "            p = (ws0y0 * wa0y0) * tot/(2*cy0) \n",
    "        return p\n",
    "    if x.Female == 0 and x.Rating == 1:\n",
    "        if x.Age_bucket == 'old':\n",
    "            p = (ws0y1 * wa1y1) * tot/(2*cy1) \n",
    "        else:\n",
    "            p = (ws0y1 * wa0y1) * tot/(2*cy1) \n",
    "        return p\n",
    "\n",
    "    if x.Female == 1 and x.Rating == 0:\n",
    "        if x.Age_bucket == 'old':\n",
    "            p = (ws1y0 * wa1y0) * tot/(2*cy0) \n",
    "        else:\n",
    "            p = (ws1y0 * wa0y0) * tot/(2*cy0) \n",
    "        return p\n",
    "    if x.Female == 1 and x.Rating == 1:\n",
    "        if x.Age_bucket == 'old':\n",
    "            p = (ws1y1 * wa1y1) * tot/(2*cy1) \n",
    "        else:\n",
    "            p = (ws1y1 * wa0y1) * tot/(2*cy1) \n",
    "        return p\n",
    "    \n",
    "    \n",
    "    \n",
    "#   (rw1*bal)*(rw2*bal)\n",
    "def assignweights_multi_2(x):\n",
    "    if x.Female == 0 and x.Rating == 0:\n",
    "        if x.Age_bucket == 'old':\n",
    "            p = (ws0y0 * wa1y0) * tot/(2*cy0) * tot/(2*cy0) \n",
    "        else:\n",
    "            p = (ws0y0 * wa0y0) * tot/(2*cy0) * tot/(2*cy0) \n",
    "        return p\n",
    "    if x.Female == 0 and x.Rating == 1:\n",
    "        if x.Age_bucket == 'old':\n",
    "            p = (ws0y1 * wa1y1) * tot/(2*cy1) * tot/(2*cy1)\n",
    "        else:\n",
    "            p = (ws0y1 * wa0y1) * tot/(2*cy1) * tot/(2*cy1)\n",
    "        return p\n",
    "\n",
    "    if x.Female == 1 and x.Rating == 0:\n",
    "        if x.Age_bucket == 'old':\n",
    "            p = (ws1y0 * wa1y0) * tot/(2*cy0) * tot/(2*cy0) \n",
    "        else:\n",
    "            p = (ws1y0 * wa0y0) * tot/(2*cy0) * tot/(2*cy0)\n",
    "        return p\n",
    "    if x.Female == 1 and x.Rating == 1:\n",
    "        if x.Age_bucket == 'old':\n",
    "            p = (ws1y1 * wa1y1) * tot/(2*cy1) * tot/(2*cy1) \n",
    "        else:\n",
    "            p = (ws1y1 * wa0y1) * tot/(2*cy1) * tot/(2*cy1) \n",
    "        return p\n",
    "    \n",
    "  #   (rw1)*(rw2)  \n",
    "def assignweights_multi_3(x):\n",
    "    if x.Female == 0 and x.Rating == 0:\n",
    "        if x.Age_bucket == 'old':\n",
    "            p = (ws0y0 * wa1y0)  \n",
    "        else:\n",
    "            p = (ws0y0 * wa0y0) \n",
    "        return p\n",
    "    if x.Female == 0 and x.Rating == 1:\n",
    "        if x.Age_bucket == 'old':\n",
    "            p = (ws0y1 * wa1y1) \n",
    "        else:\n",
    "            p = (ws0y1 * wa0y1) \n",
    "        return p\n",
    "\n",
    "    if x.Female == 1 and x.Rating == 0:\n",
    "        if x.Age_bucket == 'old':\n",
    "            p = (ws1y0 * wa1y0)  \n",
    "        else:\n",
    "            p = (ws1y0 * wa0y0)  \n",
    "        return p\n",
    "    if x.Female == 1 and x.Rating == 1:\n",
    "        if x.Age_bucket == 'old':\n",
    "            p = (ws1y1 * wa1y1)  \n",
    "        else:\n",
    "            p = (ws1y1 * wa0y1) \n",
    "        return p\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "237px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
